{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55647309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.No:1 : Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "\n",
    "#!pip install selenium\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "#connect to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")\n",
    "\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Bangalore\")\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "\n",
    "job_title=[] \n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "#Scraping title\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "job_location\n",
    "\n",
    "\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "company_name\n",
    "\n",
    "exp_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in exp_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "experience_required\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))\n",
    "\n",
    "df=pd.DataFrame({'job_title':job_title,'job_location':job_location,'company_name':company_name,'Experience Required':experience_required})\n",
    "df\n",
    "\n",
    "\n",
    "#Q.No:2 :Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "#connect to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Bangalore\")\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "\n",
    "job_title=[] \n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title\n",
    "\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "job_location\n",
    "\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "company_name\n",
    "\n",
    "exp_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in exp_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "experience_required\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))\n",
    "\n",
    "df=pd.DataFrame({'job_title':job_title,'job_location':job_location,'company_name':company_name,'Experience Required':experience_required})\n",
    "df\n",
    "\n",
    "\n",
    "#Q.No:3 :You have to use the location and salary filter.\n",
    "#You have to scrape data for “Data Scientist” designation for first 10 job results. \n",
    "#You have to scrape the job-title, job-location, company name, experience required.\n",
    "#The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "\n",
    "#!pip install selenium\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "#connect to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")\n",
    "\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys(\"Delhi\")\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()\n",
    "\n",
    "salary=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[4]/div[2]/div[2]/label/p/span[1]')\n",
    "salary.click()\n",
    "\n",
    "job_title=[] \n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "#Scraping title\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "job_location\n",
    "\n",
    "\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "company_name\n",
    "\n",
    "exp_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in exp_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "experience_required\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))\n",
    "\n",
    "df=pd.DataFrame({'job_title':job_title,'job_location':job_location,'company_name':company_name,'Experience Required':experience_required})\n",
    "df\n",
    "\n",
    "#Q.No:4 :Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "#1. Brand\n",
    "#2. Product Description\n",
    "#3. Price\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "#connect to the webdriver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "cross=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "cross.click()\n",
    "\n",
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys('sunglasses')\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "brand=[]\n",
    "price=[]\n",
    "product_description=[]\n",
    "\n",
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags[0:100]:\n",
    "    bd=i.text\n",
    "    brand.append(bd)\n",
    "   \n",
    "\n",
    "product_tags=driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "for i in product_tags[0:100]:\n",
    "    PD=i.text\n",
    "    product_description.append(PD)\n",
    "    \n",
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags[0:100]:\n",
    "    PR=i.text\n",
    "    price.append(PR)\n",
    "    \n",
    "print(len(brand),len(price),len(product_description))\n",
    "\n",
    "df=pd.DataFrame({'Brand':brand,'Price':price,'Product Description':product_description})\n",
    "    \n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "# Q.No.5:Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"http://www.flipkart.com/\")\n",
    "\n",
    "cross=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "cross.click()\n",
    "\n",
    "\n",
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys('iphone11')\n",
    "\n",
    "\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()\n",
    "\n",
    "\n",
    "\n",
    "product=driver.find_element(By.CLASS_NAME,\"_4rR01T\")\n",
    "product.click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]\n",
    "\n",
    "\n",
    "\n",
    "rating_tags=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "for i in rating_tags[0:5]:\n",
    "    RA=i.text\n",
    "    rating.append(RA)\n",
    "\n",
    "\n",
    "\n",
    "review_tags=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "for i in review_tags[0:5]:\n",
    "    RE=i.text\n",
    "    review_summary.append(RE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reviewfull_tags=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "for i in reviewfull_tags[0:5]:\n",
    "    RS=i.text\n",
    "    full_review.append(RS)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(len(rating), len(review_summary),len(full_review))\n",
    "\n",
    "\n",
    "\n",
    "df=pd.DataFrame({'Rating':rating,'Review Summary':review_summary,'Full Review':full_review})\n",
    "df\n",
    "\n",
    "\n",
    "#Q.No:6 :Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "\n",
    "\n",
    "cross=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div/button\")\n",
    "cross.click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys('Sneakers')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "brand=[]\n",
    "price=[]\n",
    "product_description=[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "brand_tags=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand_tags[0:100]:\n",
    "    bd=i.text\n",
    "    brand.append(bd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "price_tags=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "for i in price_tags[0:100]:\n",
    "    PR=i.text\n",
    "    price.append(PR)\n",
    "\n",
    "\n",
    "product_tags=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"]')\n",
    "for i in product_tags[0:100]:\n",
    "    PD=i.text\n",
    "    product_description.append(PD)\n",
    "\n",
    "\n",
    "print(len(brand),len(price),len(product_description))\n",
    "\n",
    "\n",
    "df=pd.DataFrame({'Brand':brand,\"Price\":price, \"Product Description\":product_description})\n",
    "\n",
    "df\n",
    "\n",
    "# Q,No:7:Q7: Go to webpage https://www.amazon.in/\n",
    "#Enter “Laptop” in the search field and then click the search icon.\n",
    "#Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "product.send_keys('Laptops')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div\")\n",
    "search.click()\n",
    "\n",
    "\n",
    "\n",
    "CPU=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[4]/li[14]/span/a/span\")\n",
    "CPU.click()\n",
    "\n",
    "\n",
    "\n",
    "title=[]\n",
    "rating=[]\n",
    "price=[]\n",
    "\n",
    "\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    tt=i.text\n",
    "    title.append(tt)\n",
    "\n",
    "\n",
    "\n",
    "price_tags=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in price_tags[0:10]:\n",
    "    PR=i.text\n",
    "    price.append(PR)\n",
    "\n",
    "\n",
    "\n",
    "rating_tags=driver.find_elements(By.XPATH,'//a[@class=\"a-popover-trigger a-declarative\"]//span')\n",
    "for i in rating_tags[0:10]:\n",
    "    RA=i.text\n",
    "    rating.append(RA)\n",
    "\n",
    "\n",
    "print(len(rating), len(title),len(price))\n",
    "\n",
    "\n",
    "\n",
    "df=pd.DataFrame({'Rating':rating,'Title':title,'Price':price})\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "#Q.No:8 :Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.azquotes.com/\")\n",
    "\n",
    "topquotes=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a\")\n",
    "topquotes.click()\n",
    "\n",
    "quote=[]\n",
    "author=[]\n",
    "toq=[]\n",
    "\n",
    "quote_tags=driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "for i in quote_tags:\n",
    "    qte=i.text\n",
    "    quote.append(qte)\n",
    "quote\n",
    "\n",
    "author_tags=driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "for i in author_tags:\n",
    "    auth=i.text\n",
    "    author.append(auth)\n",
    "author\n",
    "\n",
    "typeofq_tags=driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "for i in typeofq_tags:\n",
    "    toq1=i.text\n",
    "    toq.append(toq1)\n",
    "toq\n",
    "\n",
    "print(len(quote),len(author),len(toq))\n",
    "\n",
    "df=pd.DataFrame({\"Quote\":quote,\"Author\":author,\"Type of Quotes\":toq})\n",
    "df\n",
    "\n",
    "\n",
    "#Q.No:9 :Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.jagranjosh.com/\")\n",
    "\n",
    "gk=driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div[1]/div/div[6]/div/div[1]/header/div[3]/ul/li[9]\")\n",
    "gk.click()\n",
    "\n",
    "#List of all Prime Ministers of India\n",
    "\n",
    "lop=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]\")\n",
    "lop.click()\n",
    "\n",
    "\n",
    "#Born-Dead\n",
    "#Termofoffice\n",
    "#REmark\n",
    "\n",
    "table=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div[2]/div/div[1]/div/div/div/div[4]/span/div[2]\")\n",
    "table.text\n",
    "\n",
    "#Q.No:10:Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name ,Description and Price) from https://www.motor1.com/\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.motor1.com/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(10)\n",
    "\n",
    "feature=driver.find_element(By.XPATH,'/html/body/div[3]/div[2]/div/div/div[1]/div')\n",
    "\n",
    "feature.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "feature1=driver.find_element(By.XPATH,'/html/body/div[4]/div[1]/div[3]/ul/li[5]/a')\n",
    "feature1.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "cars_details=driver.find_element(By.XPATH,'/html/body/div[3]/div[8]/div/div[1]/div[1]/div[2]/div/div[1]/h3/a')\n",
    "cars_details.click()\n",
    "\n",
    "carslist=[]\n",
    "\n",
    "cars_tags=driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in cars_tags:\n",
    "    cars1=i.text\n",
    "    carslist.append(cars1)\n",
    "carslist\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
