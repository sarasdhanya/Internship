{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae9d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.No.1 :Write a python program to display all the header tags from wikipedia.org.\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "\n",
    "url = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(url.text, 'html.parser')\n",
    "story = soup.find_all(['h1', 'h2','h3'])\n",
    "for i in story:\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "# Q.No.2:Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)\n",
    "#and make data frame.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "page=requests.get(\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\")\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "titles=[]\n",
    "for i in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    titles.append(i.text)\n",
    "titles[:100]\n",
    "\n",
    "title1=[]\n",
    "for title2 in titles:\n",
    "    title1.append(re.sub('\\n',' ',title2))\n",
    "title1\n",
    "\n",
    "\n",
    "rating=[]\n",
    "for i in soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "    rating.append(i.text)\n",
    "rating[:100]\n",
    "\n",
    "rating1=[]\n",
    "for rating2 in rating:\n",
    "    rating1.append(re.sub('\\n',' ',rating2))\n",
    "rating1\n",
    "\n",
    "yor=[]\n",
    "for i in soup.find_all('span',class_=\"secondaryInfo\"):\n",
    "    yor.append(i.text)\n",
    "yor[:100]\n",
    "\n",
    "df=pd.DataFrame({\"Titles\":title1,\"Year of Release\":yor,\"Rating\":rating1})\n",
    "df[:100]\n",
    "\n",
    "#Q.No.3 : Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of\n",
    "#release) and make data frame.\n",
    "    \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "page=requests.get(\"https://www.imdb.com/india/top-rated-indian-movies/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=461131e5-5af0-4e50-bee2-223fad1e00ca&pf_rd_r=W05BARF8252XMZVF4AKP&pf_rd_s=center-1&pf_rd_t=60601&pf_rd_i=india.toprated&ref_=fea_india_ss_toprated_india_tr_india250_hd\")\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "titles=[]\n",
    "for i in soup.find_all('td',class_=\"titleColumn\"):\n",
    "    titles.append(i.text)\n",
    "titles[:100]\n",
    "\n",
    "title1=[]\n",
    "for title2 in titles:\n",
    "    title1.append(re.sub('\\n',' ',title2))\n",
    "title1\n",
    "\n",
    "\n",
    "rating=[]\n",
    "for i in soup.find_all('td',class_=\"ratingColumn imdbRating\"):\n",
    "    rating.append(i.text)\n",
    "rating[:100]\n",
    "\n",
    "rating1=[]\n",
    "for rating2 in rating:\n",
    "    rating1.append(re.sub('\\n',' ',rating2))\n",
    "rating1\n",
    "\n",
    "\n",
    "yor=[]\n",
    "for i in soup.find_all('span',class_=\"secondaryInfo\"):\n",
    "    yor.append(i.text)\n",
    "yor[:100]\n",
    "\n",
    "df=pd.DataFrame({\"Titles\":title1,\"Year of Release\":yor,\"Rating\":rating1})\n",
    "df[:100]\n",
    "\n",
    "#Q.No.4: Write s python program to display list of respected former presidents of India(i.e. Name , Term of office)\n",
    "#from https://presidentofindia.nic.in/former-presidents.htm\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "page=requests.get(\"https://presidentofindia.nic.in/former-presidents.htm\")\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "titles=[]\n",
    "for i in soup.find_all('h3'):\n",
    "    titles.append(i.text)\n",
    "titles\n",
    "\n",
    "tof=[]\n",
    "for i in soup.find_all('p'):\n",
    "    tof.append(i.text)\n",
    "tof\n",
    "\n",
    "details=[]\n",
    "for i in soup.find_all('div',class_=\"presidentListing\"):\n",
    "    details.append(i.text)\n",
    "details\n",
    "\n",
    "details1=[]\n",
    "for details2 in details:  \n",
    "   details1.append(re.sub('\\n',' ',details2))\n",
    "details1\n",
    "\n",
    "\n",
    "df=pd.DataFrame({\"President list\":details1})\n",
    "df\n",
    "\n",
    "# Q.No.5:Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "# 5a: Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "#Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "country=[]\n",
    "for i in soup.find_all(\"span\",class_=\"u-hide-phablet\"):\n",
    "    country.append(i.text)\n",
    "country\n",
    "\n",
    "\n",
    "matches=[]\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    matches.append(i.text)\n",
    "matches\n",
    "\n",
    "rating=[]\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating.append(i.text)\n",
    "rating\n",
    "\n",
    "print(\"Country\",country)\n",
    "print(\"Matches\",matches)\n",
    "print(\"Rating\",rating)\n",
    "\n",
    "\n",
    "# 5b:Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")\n",
    "\n",
    "page\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "#Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "player_name=[]\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player_name.append(i.text)\n",
    "player_name[:10]\n",
    "\n",
    "\n",
    "team=[]\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text)\n",
    "team[:10]\n",
    "\n",
    "rating=[]\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text)\n",
    "rating[:10]\n",
    "\n",
    "#print(\"Player\",player_name)\n",
    "#print(\"Team\",team)\n",
    "#print(\"Rating\",rating)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df=pd.DataFrame({\"Player\":player_name,\"Team\": team, \"Rating\":rating})\n",
    "\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "#5c:Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "\n",
    "page\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "#Top 10 ODI bowlers along with the records of their team and rating.\n",
    "player_name=[]\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player_name.append(i.text)\n",
    "player_name[:10]\n",
    "\n",
    "\n",
    "team=[]\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text)\n",
    "team[:10]\n",
    "\n",
    "rating=[]\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text)\n",
    "rating[:10]\n",
    "\n",
    "#print(\"Player\",player_name)\n",
    "#print(\"Team\",team)\n",
    "#print(\"Rating\",rating)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df=pd.DataFrame({\"Player\":player_name,\"Team\": team, \"Rating\":rating})\n",
    "\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "#Q.No:6 :Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape:\n",
    "#6a:Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "#Top 10 ODI teams in Women’s cricket along with the records for matches, points and rating.\n",
    "country=[]\n",
    "for i in soup.find_all(\"span\",class_=\"u-hide-phablet\"):\n",
    "    country.append(i.text)\n",
    "country\n",
    "\n",
    "\n",
    "matches=[]\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    matches.append(i.text)\n",
    "matches\n",
    "\n",
    "rating=[]\n",
    "for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rating.append(i.text)\n",
    "rating\n",
    "\n",
    "print(\"Country\",country)\n",
    "print(\"Matches\",matches)\n",
    "print(\"Rating\",rating)\n",
    "\n",
    "#6B:Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")\n",
    "\n",
    "page\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "#Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "player_name=[]\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player_name.append(i.text)\n",
    "player_name[:10]\n",
    "\n",
    "\n",
    "team=[]\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text)\n",
    "team[:10]\n",
    "\n",
    "rating=[]\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text)\n",
    "rating[:10]\n",
    "\n",
    "#print(\"Player\",player_name)\n",
    "#print(\"Team\",team)\n",
    "#print(\"Rating\",rating)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df=pd.DataFrame({\"Player\":player_name,\"Team\": team, \"Rating\":rating})\n",
    "\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "#6C:Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling\")\n",
    "\n",
    "page\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "#Top 10 ODI bowlers along with the records of their team and rating.\n",
    "player_name=[]\n",
    "for i in soup.find_all(\"td\",class_=\"table-body__cell rankings-table__name name\"):\n",
    "    player_name.append(i.text)\n",
    "player_name[:10]\n",
    "\n",
    "\n",
    "team=[]\n",
    "for i in soup.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    team.append(i.text)\n",
    "team[:10]\n",
    "\n",
    "rating=[]\n",
    "for i in soup.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rating.append(i.text)\n",
    "rating[:10]\n",
    "\n",
    "#print(\"Player\",player_name)\n",
    "#print(\"Team\",team)\n",
    "#print(\"Rating\",rating)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df=pd.DataFrame({\"Player\":player_name,\"Team\": team, \"Rating\":rating})\n",
    "\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "#Q.No:7 Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n",
    "#i) Headline\n",
    "#ii) Time\n",
    "#iii) News Link\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "page=requests.get('https://www.cnbc.com/world/?region=world')\n",
    "page\n",
    "\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "\n",
    "# # Headline\n",
    "\n",
    "\n",
    "headline=[]\n",
    "for i in soup.find_all('div',class_='RiverHeadline-headline RiverHeadline-hasThumbnail'):\n",
    "   headline.append(i.text)\n",
    "headline\n",
    "\n",
    "\n",
    "# # Time\n",
    "\n",
    "\n",
    "time=[]\n",
    "for i in soup.find_all('time',class_='LatestNews-timestamp'):\n",
    "   time.append(i.text)\n",
    "time\n",
    "\n",
    "print(\"Headlines\",headline)\n",
    "print(\"Time\",time)\n",
    "\n",
    "#Q.No:8 .Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "#https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "\n",
    "#https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page=requests.get(\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\")\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "paper_title=[]\n",
    "for i in soup.find_all('h2',class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    paper_title.append(i.text)\n",
    "paper_title\n",
    "\n",
    "author=[]\n",
    "for i in soup.find_all('span',class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    author.append(i.text)\n",
    "author\n",
    "\n",
    "pubdate=[]\n",
    "for i in soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    pubdate.append(i.text)\n",
    "pubdate\n",
    "\n",
    "    \n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Article':paper_title,\"Author\":author,\"Published Date\":pubdate})\n",
    "df\n",
    "\n",
    "\n",
    "#Q.No:9 :Write a python program to scrape mentioned details from dineout.co.in :\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "page=requests.get(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "title=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    title.append(i.text)\n",
    "title\n",
    "\n",
    "\n",
    "\n",
    "rt=[]\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    rt.append(i.text)\n",
    "rt\n",
    "\n",
    "price=[]\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    price.append(i.text)\n",
    "price\n",
    "\n",
    "images=[]\n",
    "for i in soup.find_all('img',class_=\"no-img\"):\n",
    "    images.append(i.get('data-src'))\n",
    "images\n",
    "    \n",
    "    \n",
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Restaurant\":title,\"Price\":price,\"Ratings\":rt,\"Images_Url\":images})\n",
    "df\n",
    "\n",
    "#Q.No:10 :Write a python program to scrape the details of top publications from Google Scholar from\n",
    "#https://scholar.google.com/citations?view_op=top_venues&hl=en\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "page=requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "page\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "rank=[]\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text)\n",
    "rank\n",
    "\n",
    "pubcl=[]\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "    pubcl.append(i.text)\n",
    "pubcl\n",
    "\n",
    "h5=[]\n",
    "for i in soup.find_all('a',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5.append(i.text)\n",
    "h5\n",
    "\n",
    "h51=[]\n",
    "for i in soup.find_all('span',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h51.append(i.text)\n",
    "h51\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Rank\":rank,\"Publication\":pubcl,\"h5_index\":h5,\"h5_median\":h51})\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
