{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "184ad42b",
   "metadata": {},
   "source": [
    "# Q.No.1Scrape the details of most viewed videos on YouTube from Wikipedia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c004c41a",
   "metadata": {},
   "source": [
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e5fc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Uploader/artist</th>\n",
       "      <th>Date of upload</th>\n",
       "      <th>Views(in billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[24]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Wheels on the Bus\"[25]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[26]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[35]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[36]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[42]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Faded\"[43]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Girls Like You\"[45]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[50]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[4]   \n",
       "1    2.                                   \"Despacito\"[7]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[14]   \n",
       "3    4.                                  \"Bath Song\"[15]   \n",
       "4    5.                               \"Shape of You\"[16]   \n",
       "5    6.                              \"See You Again\"[18]   \n",
       "6    7.                \"Phonics Song with Two Words\"[23]   \n",
       "7    8.                                \"Uptown Funk\"[24]   \n",
       "8    9.                          \"Wheels on the Bus\"[25]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[26]   \n",
       "10  11.                              \"Gangnam Style\"[27]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12  13.                             \"Dame Tu Cosita\"[33]   \n",
       "13  14.                                      \"Sugar\"[34]   \n",
       "14  15.                                       \"Roar\"[35]   \n",
       "15  16.                             \"Counting Stars\"[36]   \n",
       "16  17.                                     \"Axel F\"[37]   \n",
       "17  18.                                      \"Sorry\"[38]   \n",
       "18  19.                          \"Thinking Out Loud\"[39]   \n",
       "19  20.                        \"Baa Baa Black Sheep\"[40]   \n",
       "20  21.                                 \"Dark Horse\"[41]   \n",
       "21  22.           \"Waka Waka (This Time for Africa)\"[42]   \n",
       "22  23.                                      \"Faded\"[43]   \n",
       "23  24.                                 \"Let Her Go\"[44]   \n",
       "24  25.                             \"Girls Like You\"[45]   \n",
       "25  26.                                    \"Perfect\"[46]   \n",
       "26  27.                                   \"Bailando\"[47]   \n",
       "27  28.                                    \"Lean On\"[48]   \n",
       "28  29.          \"Humpty the train on a fruits ride\"[49]   \n",
       "29  30.                             \"Lakdi Ki Kathi\"[50]   \n",
       "\n",
       "                                  Uploader/artist     Date of upload  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                      Luis Fonsi   January 12, 2017   \n",
       "2                                     LooLoo Kids    October 8, 2016   \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "4                                      Ed Sheeran   January 30, 2017   \n",
       "5                                     Wiz Khalifa      April 6, 2015   \n",
       "6                                       ChuChu TV      March 6, 2014   \n",
       "7                                     Mark Ronson  November 19, 2014   \n",
       "8                      Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "9                                     Miroshka TV  February 27, 2018   \n",
       "10                                            Psy      July 15, 2012   \n",
       "11                                     Get Movies   January 31, 2012   \n",
       "12                                      El Chombo      April 5, 2018   \n",
       "13                                       Maroon 5   January 14, 2015   \n",
       "14                                     Katy Perry  September 5, 2013   \n",
       "15                                    OneRepublic       May 31, 2013   \n",
       "16                                     Crazy Frog      June 16, 2009   \n",
       "17                                  Justin Bieber   October 22, 2015   \n",
       "18                                     Ed Sheeran    October 7, 2014   \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "20                                     Katy Perry  February 20, 2014   \n",
       "21                                        Shakira       June 4, 2010   \n",
       "22                                    Alan Walker   December 3, 2015   \n",
       "23                                      Passenger      July 25, 2012   \n",
       "24                                       Maroon 5       May 31, 2018   \n",
       "25                                     Ed Sheeran   November 9, 2017   \n",
       "26                               Enrique Iglesias     April 11, 2014   \n",
       "27                                    Major Lazer     March 22, 2015   \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "29                                   Jingle Toons      June 14, 2018   \n",
       "\n",
       "   Views(in billion)  \n",
       "0              12.00  \n",
       "1               8.05  \n",
       "2               6.57  \n",
       "3               5.89  \n",
       "4               5.88  \n",
       "5               5.74  \n",
       "6               5.08  \n",
       "7               4.79  \n",
       "8               4.77  \n",
       "9               4.76  \n",
       "10              4.64  \n",
       "11              4.52  \n",
       "12              4.18  \n",
       "13              3.80  \n",
       "14              3.70  \n",
       "15              3.70  \n",
       "16              3.67  \n",
       "17              3.62  \n",
       "18              3.53  \n",
       "19              3.46  \n",
       "20              3.42  \n",
       "21              3.40  \n",
       "22              3.38  \n",
       "23              3.36  \n",
       "24              3.35  \n",
       "25              3.33  \n",
       "26              3.31  \n",
       "27              3.31  \n",
       "28              3.26  \n",
       "29              3.24  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,ElementNotInteractableException\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Activating the chrome browser\n",
    "driver=webdriver.Chrome(\"chromedriver.exe\") \n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "# Opening the wikipedia\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "# Rank\n",
    "# Name\n",
    "# Artist\n",
    "# Upload date\n",
    "# Views\n",
    "\n",
    "# scraping Rank of the videos\n",
    "Name=[]\n",
    "try:\n",
    "    names=driver.find_elements(By.XPATH,'/html/body/div[3]/div[3]/div[5]/div[1]/table[2]/tbody/tr/td[2]')\n",
    "    for i in names:\n",
    "        name1=i.text\n",
    "        Name.append(name1)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"-\")\n",
    "Name\n",
    "\n",
    "Rank=[]\n",
    "try:\n",
    "    ranks=driver.find_elements(By.XPATH,'/html/body/div[3]/div[3]/div[5]/div[1]/table[2]/tbody/tr/td[1]')\n",
    "    for i in ranks:\n",
    "        rank1=i.text\n",
    "        Rank.append(rank1)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"-\")\n",
    "Rank\n",
    "\n",
    "Artist=[]\n",
    "try:\n",
    "    artists=driver.find_elements(By.XPATH,'/html/body/div[3]/div[3]/div[5]/div[1]/table[2]/tbody/tr/td[3]')\n",
    "    for i in artists:\n",
    "        artist1=i.text\n",
    "        Artist.append(artist1)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"-\")\n",
    "Artist\n",
    "\n",
    "   \n",
    "Date=[]\n",
    "try:\n",
    "    date=driver.find_elements(By.XPATH,'/html/body/div[3]/div[3]/div[5]/div[1]/table[2]/tbody/tr/td[5]')\n",
    "    for i in date:\n",
    "        date1=i.text\n",
    "        Date.append(date1)\n",
    "except NoSuchElementException:\n",
    "    Date.append(\"-\")\n",
    "Date\n",
    "\n",
    "Views=[]\n",
    "try:\n",
    "    view=driver.find_elements(By.XPATH,'/html/body/div[3]/div[3]/div[5]/div[1]/table[2]/tbody/tr/td[4]')\n",
    "    for i in view:\n",
    "        view1=i.text\n",
    "        Views.append(view1)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"-\")\n",
    "Views\n",
    "\n",
    "print(len(Name),len(Rank),len(Artist),len(Date),len(Views))\n",
    "\n",
    "df=pd.DataFrame({\"Rank\":Rank,\n",
    "                 \"Name\":Name,\n",
    "                \"Uploader/artist\":Artist,\n",
    "                \"Date of upload\":Date,\n",
    "                \"Views(in billion)\":Views})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2ff1ef",
   "metadata": {},
   "source": [
    "# Q.No.2Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3cf74b",
   "metadata": {},
   "source": [
    "You need to find following details: A) Match title (I.e. 1st ODI) B) Series C) Place D) Date E) Time Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6281ddf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 8 8 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4th T20I -</td>\n",
       "      <td>INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19...</td>\n",
       "      <td>Steyn City School Ground,</td>\n",
       "      <td>2 JAN 2023</td>\n",
       "      <td>5:15 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23\\n3 ...</td>\n",
       "      <td>Wankhede Stadium,</td>\n",
       "      <td>3 JAN 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5th T20I -</td>\n",
       "      <td>INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19...</td>\n",
       "      <td>Steyn City School Ground,</td>\n",
       "      <td>4 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2nd T20I -</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23\\n5 ...</td>\n",
       "      <td>Maharashtra Cricket Association Stadium,</td>\n",
       "      <td>5 JAN 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd T20I -</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022-23\\n7 ...</td>\n",
       "      <td>Saurashtra Cricket Association Stadium,</td>\n",
       "      <td>7 JAN 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA ODI SERIES 2022-23\\n10...</td>\n",
       "      <td>Barsapara Cricket Stadium,</td>\n",
       "      <td>10 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA ODI SERIES 2022-23\\n12...</td>\n",
       "      <td>Eden Gardens,</td>\n",
       "      <td>12 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA ODI SERIES 2022-23\\n15...</td>\n",
       "      <td>Greenfield International Stadium,</td>\n",
       "      <td>15 JAN 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Match                                             Series  \\\n",
       "0  4th T20I -  INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19...   \n",
       "1  1st T20I -  SRI LANKA TOUR OF INDIA T20 SERIES 2022-23\\n3 ...   \n",
       "2  5th T20I -  INDIA WOMEN U19 TOUR OF SOUTH AFRICA WOMEN U19...   \n",
       "3  2nd T20I -  SRI LANKA TOUR OF INDIA T20 SERIES 2022-23\\n5 ...   \n",
       "4  3rd T20I -  SRI LANKA TOUR OF INDIA T20 SERIES 2022-23\\n7 ...   \n",
       "5   1st ODI -  SRI LANKA TOUR OF INDIA ODI SERIES 2022-23\\n10...   \n",
       "6   2nd ODI -  SRI LANKA TOUR OF INDIA ODI SERIES 2022-23\\n12...   \n",
       "7   3rd ODI -  SRI LANKA TOUR OF INDIA ODI SERIES 2022-23\\n15...   \n",
       "\n",
       "                                      Place         Date         Time  \n",
       "0                 Steyn City School Ground,   2 JAN 2023  5:15 PM IST  \n",
       "1                         Wankhede Stadium,   3 JAN 2023  7:00 PM IST  \n",
       "2                 Steyn City School Ground,   4 JAN 2023  1:30 PM IST  \n",
       "3  Maharashtra Cricket Association Stadium,   5 JAN 2023  7:00 PM IST  \n",
       "4   Saurashtra Cricket Association Stadium,   7 JAN 2023  7:00 PM IST  \n",
       "5                Barsapara Cricket Stadium,  10 JAN 2023  1:30 PM IST  \n",
       "6                             Eden Gardens,  12 JAN 2023  1:30 PM IST  \n",
       "7         Greenfield International Stadium,  15 JAN 2023  1:30 PM IST  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,ElementNotInteractableException\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "time.sleep(5)\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "intl=driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "intl.click()\n",
    "\n",
    "#Match title (I.e. 1st ODI) \n",
    "#Series \n",
    "#Place \n",
    "#Date \n",
    "#Time Note:\n",
    "\n",
    "\n",
    "Title=[]\n",
    "try:\n",
    "    titles=driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "    for i in titles:\n",
    "        title1=i.text\n",
    "        Title.append(title1)\n",
    "except NoSuchElementException:\n",
    "    Title.append(\"-\")\n",
    "Title\n",
    "\n",
    "Series=[]\n",
    "try:\n",
    "    series=driver.find_elements(By.XPATH,'//div[@class=\"fixture-card-top\"]')\n",
    "    for i in series:\n",
    "        series1=i.text\n",
    "        Series.append(series1)\n",
    "except NoSuchElementException:\n",
    "    Series.append(\"-\")\n",
    "Series\n",
    "\n",
    "Place=[]\n",
    "try:\n",
    "    places=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]')\n",
    "    for i in places:\n",
    "        place1=i.text\n",
    "        Place.append(place1)\n",
    "except NoSuchElementException:\n",
    "    Place.append(\"-\")\n",
    "Place\n",
    "\n",
    "Date=[]\n",
    "try:\n",
    "    dates=driver.find_elements(By.XPATH,'//div[@class=\"match-card-left match-schedule\"]')\n",
    "    for i in dates:\n",
    "        date1=i.text\n",
    "        Date.append(date1)\n",
    "except NoSuchElementException:\n",
    "    Date.append(\"-\")\n",
    "Date\n",
    "\n",
    "Time=[]\n",
    "try:\n",
    "    times=driver.find_elements(By.XPATH,'//div[@class=\"match-card-right match-schedule \"]')\n",
    "    for i in times:\n",
    "        time1=i.text\n",
    "        Time.append(time1)\n",
    "except NoSuchElementException:\n",
    "    Time.append(\"-\")\n",
    "Time\n",
    "\n",
    "print(len(Title),len(Series),len(Place),len(Date),len(Time))\n",
    "\n",
    "df=pd.DataFrame({\"Match\":Title,\"Series\":Series,\"Place\":Place,\"Date\":Date, \"Time\":Time})          \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8001d428",
   "metadata": {},
   "source": [
    "# Q.No.3Scrape the details of selenium exception from guru99.com. Url = https://www.guru99.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28bae14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type of Exception in Selenium</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. ElementNotVisibleException:</td>\n",
       "      <td>1. ElementNotVisibleException: This type of Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. ElementNotSelectableException:</td>\n",
       "      <td>2. ElementNotSelectableException: This Seleniu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. NoSuchElementException:</td>\n",
       "      <td>3. NoSuchElementException: This Exception occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. NoSuchFrameException:</td>\n",
       "      <td>4. NoSuchFrameException: This Exception occurs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. NoAlertPresentException:</td>\n",
       "      <td>5. NoAlertPresentException: This Exception occ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6. NoSuchWindowException:</td>\n",
       "      <td>6. NoSuchWindowException: This Exception occur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7. StaleElementReferenceException:</td>\n",
       "      <td>7. StaleElementReferenceException: This Seleni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8. SessionNotFoundException:</td>\n",
       "      <td>8. SessionNotFoundException: The WebDriver is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9. TimeoutException:</td>\n",
       "      <td>9. TimeoutException: Thrown when there is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10. WebDriverException:</td>\n",
       "      <td>10. WebDriverException: This Exception takes p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11. ConnectionClosedException:</td>\n",
       "      <td>11. ConnectionClosedException: This type of Ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12. ElementClickInterceptedException:</td>\n",
       "      <td>12. ElementClickInterceptedException: The comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13. ElementNotInteractableException:</td>\n",
       "      <td>13. ElementNotInteractableException: This Sele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14. ErrorInResponseException:</td>\n",
       "      <td>14. ErrorInResponseException: This happens whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15. ErrorHandler.UnknownServerException:</td>\n",
       "      <td>15. ErrorHandler.UnknownServerException: Excep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16. ImeActivationFailedException:</td>\n",
       "      <td>16. ImeActivationFailedException: This expecta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17. ImeNotAvailableException:</td>\n",
       "      <td>17. ImeNotAvailableException: It takes place w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18. InsecureCertificateException:</td>\n",
       "      <td>18. InsecureCertificateException: Navigation m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19. InvalidArgumentException:</td>\n",
       "      <td>19. InvalidArgumentException: It occurs when a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20. InvalidCookieDomainException:</td>\n",
       "      <td>20. InvalidCookieDomainException: This happens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21. InvalidCoordinatesException:</td>\n",
       "      <td>21. InvalidCoordinatesException: This type of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22. InvalidElementStateException:</td>\n",
       "      <td>22. InvalidElementStateException: It occurs wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23. InvalidSessionIdException:</td>\n",
       "      <td>23. InvalidSessionIdException: This Exception ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24. InvalidSwitchToTargetException:</td>\n",
       "      <td>24. InvalidSwitchToTargetException: This occur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25. JavascriptException:</td>\n",
       "      <td>25. JavascriptException: This issue occurs whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26. JsonException:</td>\n",
       "      <td>26. JsonException: It occurs when you afford t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27. NoSuchAttributeException:</td>\n",
       "      <td>27. NoSuchAttributeException: This kind of Exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28. MoveTargetOutOfBoundsException:</td>\n",
       "      <td>28. MoveTargetOutOfBoundsException: It takes p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29. NoSuchContextException:</td>\n",
       "      <td>29. NoSuchContextException: ContextAware does ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30. NoSuchCookieException:</td>\n",
       "      <td>30. NoSuchCookieException: This Exception occu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31. NotFoundException:</td>\n",
       "      <td>31. NotFoundException: This Exception is a sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32. RemoteDriverServerException:</td>\n",
       "      <td>32. RemoteDriverServerException: This Selenium...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33. ScreenshotException:</td>\n",
       "      <td>33. ScreenshotException: It is not possible to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34. SessionNotCreatedException:</td>\n",
       "      <td>34. SessionNotCreatedException: It happens whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35. UnableToSetCookieException:</td>\n",
       "      <td>35. UnableToSetCookieException: This occurs if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36. UnexpectedTagNameException:</td>\n",
       "      <td>36. UnexpectedTagNameException: Happens if a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37. UnhandledAlertException:</td>\n",
       "      <td>37. UnhandledAlertException: This expectation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38. UnexpectedAlertPresentException:</td>\n",
       "      <td>38. UnexpectedAlertPresentException: It occurs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39. UnknownMethodException:</td>\n",
       "      <td>39. UnknownMethodException: This Exception hap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40. UnreachableBrowserException:</td>\n",
       "      <td>40. UnreachableBrowserException: This Exceptio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41. UnsupportedCommandException:</td>\n",
       "      <td>41. UnsupportedCommandException: This occurs w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type of Exception in Selenium  \\\n",
       "0             1. ElementNotVisibleException:   \n",
       "1          2. ElementNotSelectableException:   \n",
       "2                 3. NoSuchElementException:   \n",
       "3                   4. NoSuchFrameException:   \n",
       "4                5. NoAlertPresentException:   \n",
       "5                  6. NoSuchWindowException:   \n",
       "6         7. StaleElementReferenceException:   \n",
       "7               8. SessionNotFoundException:   \n",
       "8                       9. TimeoutException:   \n",
       "9                    10. WebDriverException:   \n",
       "10            11. ConnectionClosedException:   \n",
       "11     12. ElementClickInterceptedException:   \n",
       "12      13. ElementNotInteractableException:   \n",
       "13             14. ErrorInResponseException:   \n",
       "14  15. ErrorHandler.UnknownServerException:   \n",
       "15         16. ImeActivationFailedException:   \n",
       "16             17. ImeNotAvailableException:   \n",
       "17         18. InsecureCertificateException:   \n",
       "18             19. InvalidArgumentException:   \n",
       "19         20. InvalidCookieDomainException:   \n",
       "20          21. InvalidCoordinatesException:   \n",
       "21         22. InvalidElementStateException:   \n",
       "22            23. InvalidSessionIdException:   \n",
       "23       24. InvalidSwitchToTargetException:   \n",
       "24                  25. JavascriptException:   \n",
       "25                        26. JsonException:   \n",
       "26             27. NoSuchAttributeException:   \n",
       "27       28. MoveTargetOutOfBoundsException:   \n",
       "28               29. NoSuchContextException:   \n",
       "29                30. NoSuchCookieException:   \n",
       "30                    31. NotFoundException:   \n",
       "31          32. RemoteDriverServerException:   \n",
       "32                  33. ScreenshotException:   \n",
       "33           34. SessionNotCreatedException:   \n",
       "34           35. UnableToSetCookieException:   \n",
       "35           36. UnexpectedTagNameException:   \n",
       "36              37. UnhandledAlertException:   \n",
       "37      38. UnexpectedAlertPresentException:   \n",
       "38               39. UnknownMethodException:   \n",
       "39          40. UnreachableBrowserException:   \n",
       "40          41. UnsupportedCommandException:   \n",
       "\n",
       "                                          Description  \n",
       "0   1. ElementNotVisibleException: This type of Se...  \n",
       "1   2. ElementNotSelectableException: This Seleniu...  \n",
       "2   3. NoSuchElementException: This Exception occu...  \n",
       "3   4. NoSuchFrameException: This Exception occurs...  \n",
       "4   5. NoAlertPresentException: This Exception occ...  \n",
       "5   6. NoSuchWindowException: This Exception occur...  \n",
       "6   7. StaleElementReferenceException: This Seleni...  \n",
       "7   8. SessionNotFoundException: The WebDriver is ...  \n",
       "8   9. TimeoutException: Thrown when there is not ...  \n",
       "9   10. WebDriverException: This Exception takes p...  \n",
       "10  11. ConnectionClosedException: This type of Ex...  \n",
       "11  12. ElementClickInterceptedException: The comm...  \n",
       "12  13. ElementNotInteractableException: This Sele...  \n",
       "13  14. ErrorInResponseException: This happens whi...  \n",
       "14  15. ErrorHandler.UnknownServerException: Excep...  \n",
       "15  16. ImeActivationFailedException: This expecta...  \n",
       "16  17. ImeNotAvailableException: It takes place w...  \n",
       "17  18. InsecureCertificateException: Navigation m...  \n",
       "18  19. InvalidArgumentException: It occurs when a...  \n",
       "19  20. InvalidCookieDomainException: This happens...  \n",
       "20  21. InvalidCoordinatesException: This type of ...  \n",
       "21  22. InvalidElementStateException: It occurs wh...  \n",
       "22  23. InvalidSessionIdException: This Exception ...  \n",
       "23  24. InvalidSwitchToTargetException: This occur...  \n",
       "24  25. JavascriptException: This issue occurs whi...  \n",
       "25  26. JsonException: It occurs when you afford t...  \n",
       "26  27. NoSuchAttributeException: This kind of Exc...  \n",
       "27  28. MoveTargetOutOfBoundsException: It takes p...  \n",
       "28  29. NoSuchContextException: ContextAware does ...  \n",
       "29  30. NoSuchCookieException: This Exception occu...  \n",
       "30  31. NotFoundException: This Exception is a sub...  \n",
       "31  32. RemoteDriverServerException: This Selenium...  \n",
       "32  33. ScreenshotException: It is not possible to...  \n",
       "33  34. SessionNotCreatedException: It happens whe...  \n",
       "34  35. UnableToSetCookieException: This occurs if...  \n",
       "35  36. UnexpectedTagNameException: Happens if a s...  \n",
       "36  37. UnhandledAlertException: This expectation ...  \n",
       "37  38. UnexpectedAlertPresentException: It occurs...  \n",
       "38  39. UnknownMethodException: This Exception hap...  \n",
       "39  40. UnreachableBrowserException: This Exceptio...  \n",
       "40  41. UnsupportedCommandException: This occurs w...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,ElementNotInteractableException\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "time.sleep(5)\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.guru99.com/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "selenium=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div[1]/div[2]/div[1]/div/ul[1]/li[3]/a')\n",
    "selenium.click()\n",
    "\n",
    "exception=driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/table[5]/tbody/tr[34]/td[1]/a')\n",
    "exception.click()\n",
    "\n",
    "Name=[]\n",
    "try:\n",
    "    name=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p/strong')\n",
    "    for i in name[0:41]:\n",
    "        name1=i.text\n",
    "        Name.append(name1)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"-\")\n",
    "Name\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Desc=[]\n",
    "try:\n",
    "    desc=driver.find_elements(By.XPATH,'/html/body/div[1]/div/div/div/main/div/article/div/div/p')\n",
    "    for i in desc[0:41]:\n",
    "        desc1=i.text\n",
    "        Desc.append(desc1)\n",
    "except NoSuchElementException:\n",
    "    Desc.append(\"-\")\n",
    "Desc\n",
    "time.sleep(5)\n",
    "\n",
    "print(len(Name),len(Desc))\n",
    "df=pd.DataFrame({\"Type of Exception in Selenium\":Name,\"Description\":Desc})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191fe19a",
   "metadata": {},
   "source": [
    "# Q.No.4 :Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78de4b5",
   "metadata": {},
   "source": [
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e8b26d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>GSDP(18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP(Billion_$)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(19-20) GSDP(18-19) Share(18-19)  \\\n",
       "0     1                Maharashtra           -   2,632,792       13.94%   \n",
       "1     2                 Tamil Nadu   1,845,853   1,630,208        8.63%   \n",
       "2     3              Uttar Pradesh   1,687,818   1,584,764        8.39%   \n",
       "3     4                    Gujarat           -   1,502,899        7.96%   \n",
       "4     5                  Karnataka   1,631,977   1,493,127        7.91%   \n",
       "5     6                West Bengal   1,253,832   1,089,898        5.77%   \n",
       "6     7                  Rajasthan   1,020,989     942,586        4.99%   \n",
       "7     8             Andhra Pradesh     972,782     862,957        4.57%   \n",
       "8     9                  Telangana     969,604     861,031        4.56%   \n",
       "9    10             Madhya Pradesh     906,672     809,592        4.29%   \n",
       "10   11                     Kerala           -     781,653        4.14%   \n",
       "11   12                      Delhi     856,112     774,870        4.10%   \n",
       "12   13                    Haryana     831,610     734,163        3.89%   \n",
       "13   14                      Bihar     611,804     530,363        2.81%   \n",
       "14   15                     Punjab     574,760     526,376        2.79%   \n",
       "15   16                     Odisha     521,275     487,805        2.58%   \n",
       "16   17                      Assam           -     315,881        1.67%   \n",
       "17   18               Chhattisgarh     329,180     304,063        1.61%   \n",
       "18   19                  Jharkhand     328,598     297,204        1.57%   \n",
       "19   20                Uttarakhand           -     245,895        1.30%   \n",
       "20   21            Jammu & Kashmir           -     155,956        0.83%   \n",
       "21   22           Himachal Pradesh     165,472     153,845        0.81%   \n",
       "22   23                        Goa      80,449      73,170        0.39%   \n",
       "23   24                    Tripura      55,984      49,845        0.26%   \n",
       "24   25                 Chandigarh           -      42,114        0.22%   \n",
       "25   26                 Puducherry      38,253      34,433        0.18%   \n",
       "26   27                  Meghalaya      36,572      33,481        0.18%   \n",
       "27   28                     Sikkim      32,496      28,723        0.15%   \n",
       "28   29                    Manipur      31,790      27,870        0.15%   \n",
       "29   30                   Nagaland           -      27,283        0.14%   \n",
       "30   31          Arunachal Pradesh           -      24,603        0.13%   \n",
       "31   32                    Mizoram      26,503      22,287        0.12%   \n",
       "32   33  Andaman & Nicobar Islands           -           -            -   \n",
       "\n",
       "   GDP(Billion_$)  \n",
       "0         399.921  \n",
       "1         247.629  \n",
       "2         240.726  \n",
       "3         228.290  \n",
       "4         226.806  \n",
       "5         165.556  \n",
       "6         143.179  \n",
       "7         131.083  \n",
       "8         130.791  \n",
       "9         122.977  \n",
       "10        118.733  \n",
       "11        117.703  \n",
       "12        111.519  \n",
       "13         80.562  \n",
       "14         79.957  \n",
       "15         74.098  \n",
       "16         47.982  \n",
       "17         46.187  \n",
       "18         45.145  \n",
       "19         37.351  \n",
       "20         23.690  \n",
       "21         23.369  \n",
       "22         11.115  \n",
       "23          7.571  \n",
       "24          6.397  \n",
       "25          5.230  \n",
       "26          5.086  \n",
       "27          4.363  \n",
       "28          4.233  \n",
       "29          4.144  \n",
       "30          3.737  \n",
       "31          3.385  \n",
       "32              -  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,ElementNotInteractableException\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "time.sleep(5)\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.statisticstimes.com/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "economy=driver.find_element(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "economy.click()\n",
    "time.sleep(5)\n",
    "\n",
    "india_url=[]\n",
    "url=driver.find_elements(By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "for i in url:\n",
    "    india_url.append(i.get_attribute(\"href\"))\n",
    "india_url\n",
    "\n",
    "for india in india_url:\n",
    "    driver.get(india)\n",
    "    \n",
    "goi=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "goi.click()\n",
    "time.sleep(5)\n",
    "#Rank\n",
    "# State\n",
    "#GSDP(18-19)- at current prices\n",
    "#GSDP(19-20)- at current prices\n",
    "#Share(18-19)\n",
    "# GDP($ billion)\n",
    "\n",
    "Rank=[]\n",
    "ranks=driver.find_elements(By.XPATH,'/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[1]')\n",
    "for i in ranks:\n",
    "    rank1=i.text\n",
    "    Rank.append(rank1)\n",
    "Rank\n",
    "\n",
    "State=[]\n",
    "states=driver.find_elements(By.XPATH,'/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[2]')\n",
    "for i in states:\n",
    "    state1=i.text\n",
    "    State.append(state1)\n",
    "State\n",
    "\n",
    "gsdp1819=[]\n",
    "gsdp=driver.find_elements(By.XPATH,'/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[4]')\n",
    "for i in gsdp:\n",
    "    gsdp1=i.text\n",
    "    gsdp1819.append(gsdp1)\n",
    "gsdp1819\n",
    "\n",
    "gsdp1920=[]\n",
    "gsdp2=driver.find_elements(By.XPATH,'/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[3]')\n",
    "for i in gsdp2:\n",
    "    gsdp3=i.text\n",
    "    gsdp1920.append(gsdp3)\n",
    "gsdp1920\n",
    "\n",
    "Share=[]\n",
    "share=driver.find_elements(By.XPATH,'/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[5]')\n",
    "for i in share:\n",
    "    share2=i.text\n",
    "    Share.append(share2)\n",
    "Share\n",
    "\n",
    "GDP=[]\n",
    "gdp=driver.find_elements(By.XPATH,'/html/body/div[3]/div[2]/div[5]/div[1]/div/table/tbody/tr/td[6]')\n",
    "for i in gdp:\n",
    "    gdp1=i.text\n",
    "    GDP.append(gdp1)\n",
    "GDP\n",
    "\n",
    "df=pd.DataFrame({'Rank':Rank,\n",
    "                'State':State,\n",
    "                'GSDP(19-20)':gsdp1920,\n",
    "                'GSDP(18-19)':gsdp1819,\n",
    "                'Share(18-19)':Share,\n",
    "                'GDP(Billion_$)':GDP})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd288ea",
   "metadata": {},
   "source": [
    "# Q.No.5 Scrape the details of trending repositories on Github.com. Url = https://github.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638284e",
   "metadata": {},
   "source": [
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "ASSIGNMENT\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "becb9a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAION-AI / Open-Assistant</td>\n",
       "      <td>OpenAssistant is a chat-based assistant that u...</td>\n",
       "      <td>35</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>karpathy / nanoGPT</td>\n",
       "      <td>The simplest, fastest repository for training/...</td>\n",
       "      <td>No details available</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sczhou / CodeFormer</td>\n",
       "      <td>[NeurIPS 2022] Towards Robust Blind Face Resto...</td>\n",
       "      <td>3</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DarkFlippers / unleashed-firmware</td>\n",
       "      <td>Flipper Zero Unleashed Firmware</td>\n",
       "      <td>No details available</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ytdl-org / youtube-dl</td>\n",
       "      <td>Command-line program to download videos from Y...</td>\n",
       "      <td>777</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>google / osv-scanner</td>\n",
       "      <td>Vulnerability scanner written in Go which uses...</td>\n",
       "      <td>15</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pola-rs / polars</td>\n",
       "      <td>Fast multi-threaded, hybrid-streaming DataFram...</td>\n",
       "      <td>368</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>neonbjb / tortoise-tts</td>\n",
       "      <td>A multi-voice TTS system trained with an empha...</td>\n",
       "      <td>11</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Developer-Y / cs-video-courses</td>\n",
       "      <td>List of Computer Science courses with video le...</td>\n",
       "      <td>75</td>\n",
       "      <td>No details available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dair-ai / Prompt-Engineering-Guide</td>\n",
       "      <td>🐙 Guide and resources for prompt engineering</td>\n",
       "      <td>3</td>\n",
       "      <td>No details available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ebazhanov / linkedin-skill-assessments-quizzes</td>\n",
       "      <td>Full reference of LinkedIn answers 2022 for sk...</td>\n",
       "      <td>No details available</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ocornut / imgui</td>\n",
       "      <td>Dear ImGui: Bloat-free Graphical User interfac...</td>\n",
       "      <td>313</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AmruthPillai / Reactive-Resume</td>\n",
       "      <td>A one-of-a-kind resume builder that keeps your...</td>\n",
       "      <td>84</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PRQL / prql</td>\n",
       "      <td>PRQL is a modern language for transforming dat...</td>\n",
       "      <td>No details available</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A-poc / RedTeam-Tools</td>\n",
       "      <td>Tools and Techniques for Red Team / Penetratio...</td>\n",
       "      <td>No details available</td>\n",
       "      <td>No details available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jerryjliu / gpt_index</td>\n",
       "      <td>An index created by GPT to organize external i...</td>\n",
       "      <td>No details available</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>imDazui / Tvlist-awesome-m3u-m3u8</td>\n",
       "      <td>直播源相关资源汇总 📺 💯 IPTV、M3U —— 勤洗手、戴口罩，祝愿所有人百毒不侵</td>\n",
       "      <td>No details available</td>\n",
       "      <td>No details available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aurae-runtime / aurae</td>\n",
       "      <td>Distributed systems runtime daemon written in ...</td>\n",
       "      <td>25</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>zlib-searcher / zlib-searcher</td>\n",
       "      <td>search zlib/libgen index to get ipfs_cid.</td>\n",
       "      <td>9</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BrunoLevy / learn-fpga</td>\n",
       "      <td>Learning FPGA, yosys, nextpnr, and RISC-V</td>\n",
       "      <td>11</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>alist-org / alist</td>\n",
       "      <td>🗂️A file list program that supports multiple s...</td>\n",
       "      <td>30</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>freeCodeCamp / freeCodeCamp</td>\n",
       "      <td>freeCodeCamp.org's open-source codebase and cu...</td>\n",
       "      <td>No details available</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Atlas-OS / Atlas</td>\n",
       "      <td>🚀 An open-source modification of Windows 10, d...</td>\n",
       "      <td>No details available</td>\n",
       "      <td>Batchfile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SheerSt / pokewilds</td>\n",
       "      <td>PokeWilds - A Gen 2 Game/Engine using libGDX</td>\n",
       "      <td>8</td>\n",
       "      <td>Assembly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>jwasham / coding-interview-university</td>\n",
       "      <td>A complete computer science study plan to beco...</td>\n",
       "      <td>2</td>\n",
       "      <td>No details available</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Repository title  \\\n",
       "0                        LAION-AI / Open-Assistant   \n",
       "1                               karpathy / nanoGPT   \n",
       "2                              sczhou / CodeFormer   \n",
       "3                DarkFlippers / unleashed-firmware   \n",
       "4                            ytdl-org / youtube-dl   \n",
       "5                             google / osv-scanner   \n",
       "6                                 pola-rs / polars   \n",
       "7                           neonbjb / tortoise-tts   \n",
       "8                   Developer-Y / cs-video-courses   \n",
       "9               dair-ai / Prompt-Engineering-Guide   \n",
       "10  Ebazhanov / linkedin-skill-assessments-quizzes   \n",
       "11                                 ocornut / imgui   \n",
       "12                  AmruthPillai / Reactive-Resume   \n",
       "13                                     PRQL / prql   \n",
       "14                           A-poc / RedTeam-Tools   \n",
       "15                           jerryjliu / gpt_index   \n",
       "16               imDazui / Tvlist-awesome-m3u-m3u8   \n",
       "17                           aurae-runtime / aurae   \n",
       "18                   zlib-searcher / zlib-searcher   \n",
       "19                          BrunoLevy / learn-fpga   \n",
       "20                               alist-org / alist   \n",
       "21                     freeCodeCamp / freeCodeCamp   \n",
       "22                                Atlas-OS / Atlas   \n",
       "23                             SheerSt / pokewilds   \n",
       "24           jwasham / coding-interview-university   \n",
       "\n",
       "                               Repository description    Contributors count  \\\n",
       "0   OpenAssistant is a chat-based assistant that u...                    35   \n",
       "1   The simplest, fastest repository for training/...  No details available   \n",
       "2   [NeurIPS 2022] Towards Robust Blind Face Resto...                     3   \n",
       "3                     Flipper Zero Unleashed Firmware  No details available   \n",
       "4   Command-line program to download videos from Y...                   777   \n",
       "5   Vulnerability scanner written in Go which uses...                    15   \n",
       "6   Fast multi-threaded, hybrid-streaming DataFram...                   368   \n",
       "7   A multi-voice TTS system trained with an empha...                    11   \n",
       "8   List of Computer Science courses with video le...                    75   \n",
       "9        🐙 Guide and resources for prompt engineering                     3   \n",
       "10  Full reference of LinkedIn answers 2022 for sk...  No details available   \n",
       "11  Dear ImGui: Bloat-free Graphical User interfac...                   313   \n",
       "12  A one-of-a-kind resume builder that keeps your...                    84   \n",
       "13  PRQL is a modern language for transforming dat...  No details available   \n",
       "14  Tools and Techniques for Red Team / Penetratio...  No details available   \n",
       "15  An index created by GPT to organize external i...  No details available   \n",
       "16        直播源相关资源汇总 📺 💯 IPTV、M3U —— 勤洗手、戴口罩，祝愿所有人百毒不侵  No details available   \n",
       "17  Distributed systems runtime daemon written in ...                    25   \n",
       "18          search zlib/libgen index to get ipfs_cid.                     9   \n",
       "19          Learning FPGA, yosys, nextpnr, and RISC-V                    11   \n",
       "20  🗂️A file list program that supports multiple s...                    30   \n",
       "21  freeCodeCamp.org's open-source codebase and cu...  No details available   \n",
       "22  🚀 An open-source modification of Windows 10, d...  No details available   \n",
       "23       PokeWilds - A Gen 2 Game/Engine using libGDX                     8   \n",
       "24  A complete computer science study plan to beco...                     2   \n",
       "\n",
       "           Language used  \n",
       "0       Jupyter Notebook  \n",
       "1                 Python  \n",
       "2                 Python  \n",
       "3                      C  \n",
       "4                 Python  \n",
       "5                     Go  \n",
       "6                   Rust  \n",
       "7                 Python  \n",
       "8   No details available  \n",
       "9   No details available  \n",
       "10                Python  \n",
       "11                   C++  \n",
       "12            TypeScript  \n",
       "13                  Rust  \n",
       "14  No details available  \n",
       "15                Python  \n",
       "16  No details available  \n",
       "17                  Rust  \n",
       "18            TypeScript  \n",
       "19                   C++  \n",
       "20                    Go  \n",
       "21            TypeScript  \n",
       "22             Batchfile  \n",
       "23              Assembly  \n",
       "24  No details available  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,ElementNotInteractableException\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "time.sleep(5)\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://github.com/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "explore=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "explore.click()\n",
    "\n",
    "trending_url=[]\n",
    "url=driver.find_elements(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/ul[3]/li[3]/a')\n",
    "for i in url:\n",
    "    trending_url.append(i.get_attribute(\"href\"))\n",
    "trending_url\n",
    "\n",
    "for trending in trending_url:\n",
    "    driver.get(trending)\n",
    "    \n",
    "title=[]\n",
    "title1=driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]')\n",
    "for i in title1:\n",
    "    title2=i.text\n",
    "    title.append(title2)\n",
    "title\n",
    "\n",
    "desc=[]\n",
    "desc1=driver.find_elements(By.XPATH,'/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article/p')\n",
    "for i in desc1:\n",
    "    desc2=i.text\n",
    "    desc.append(desc2)\n",
    "desc\n",
    "\n",
    "\n",
    "    \n",
    "repo_url=[]\n",
    "url=driver.find_elements(By.XPATH,'/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article/h1/a')\n",
    "for i in url:\n",
    "    repo_url.append(i.get_attribute(\"href\"))\n",
    "repo_url\n",
    "\n",
    "Contributor=[]\n",
    "language=[]\n",
    "\n",
    "for url in repo_url:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        contributors=driver.find_element(By.XPATH,'/html/body/div[1]/div[4]/div/main/turbo-frame/div/div/div/div[3]/div[2]/div/div[5]/div/h2/a/span')\n",
    "        Contributor.append(contributors.text)\n",
    "    except NoSuchElementException:\n",
    "        Contributor.append(\"No details available\")\n",
    "Contributor\n",
    "\n",
    "for url in repo_url:\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    try:\n",
    "        lang=driver.find_element(By.XPATH,'//span[@class=\"color-fg-default text-bold mr-1\"]')\n",
    "        language.append(lang.text)\n",
    "    except NoSuchElementException:\n",
    "        language.append(\"No details available\")\n",
    "        \n",
    "\n",
    "df=pd.DataFrame({\"Repository title\":title,\"Repository description\":desc,\"Contributors count\":Contributor,\"Language used\":language})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db62ba4b",
   "metadata": {},
   "source": [
    "# Q.No.6  Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cc009e",
   "metadata": {},
   "source": [
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a82649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rockin' Around The Christmas Tree</td>\n",
       "      <td>Brenda Lee</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jingle Bell Rock</td>\n",
       "      <td>Bobby Helms</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Holly Jolly Christmas</td>\n",
       "      <td>Burl Ives</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Last Christmas</td>\n",
       "      <td>Wham!</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Down Home</td>\n",
       "      <td>Jimmie Allen</td>\n",
       "      <td>-</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>One Thing At A Time</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>81</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hold Me Closer</td>\n",
       "      <td>Elton John &amp; Britney Spears</td>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Far</td>\n",
       "      <td>SZA</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>All Mine</td>\n",
       "      <td>Brent Faiyaz</td>\n",
       "      <td>95</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Song name                  Artist name  \\\n",
       "0     All I Want For Christmas Is You                 Mariah Carey   \n",
       "1   Rockin' Around The Christmas Tree                   Brenda Lee   \n",
       "2                    Jingle Bell Rock                  Bobby Helms   \n",
       "3             A Holly Jolly Christmas                    Burl Ives   \n",
       "4                      Last Christmas                        Wham!   \n",
       "..                                ...                          ...   \n",
       "95                          Down Home                 Jimmie Allen   \n",
       "96                One Thing At A Time                Morgan Wallen   \n",
       "97                     Hold Me Closer  Elton John & Britney Spears   \n",
       "98                                Far                          SZA   \n",
       "99                           All Mine                 Brent Faiyaz   \n",
       "\n",
       "   Last week Rank Peak Rank Weeks on Board  \n",
       "0               1         1             57  \n",
       "1               2         2             51  \n",
       "2               4         3             48  \n",
       "3               5         4             31  \n",
       "4               6         5             30  \n",
       "..            ...       ...            ...  \n",
       "95              -        88              5  \n",
       "96             81        37              3  \n",
       "97             89         6             17  \n",
       "98             61        61              2  \n",
       "99             95        42             20  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,ElementNotInteractableException\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "time.sleep(5)\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.billboard.com/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "# Song name\n",
    "#Artist name\n",
    "# Last week rank\n",
    "# Peak rank\n",
    "#Weeks on board\n",
    "#Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n",
    "\n",
    "options_li=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]')\n",
    "options_li.click()\n",
    "time.sleep(10)\n",
    "\n",
    "hot=driver.find_element(By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div/div[2]/span/a')\n",
    "hot.click()\n",
    "time.sleep(10)\n",
    "\n",
    "Song_list=[]\n",
    "try:\n",
    "    songs=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[1]/h3')\n",
    "    for i in songs:        \n",
    "        song1=i.text\n",
    "        Song_list.append(song1)\n",
    "except NoSuchElementException:\n",
    "    Song_list.append(\"-\")\n",
    "Song_list\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "Artist=[]\n",
    "try:\n",
    "    artist=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[1]/span')\n",
    "    for i in artist:        \n",
    "        artist1=i.text\n",
    "        Artist.append(artist1)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"-\")\n",
    "Artist\n",
    "time.sleep(5)\n",
    "\n",
    "last=[]\n",
    "\n",
    "try:\n",
    "    last_rank=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[4]/span')\n",
    "    for i in last_rank:        \n",
    "        last1=i.text\n",
    "        last.append(last1)\n",
    "except NoSuchElementException:\n",
    "    last.append(\"-\")\n",
    "last\n",
    "time.sleep(5)\n",
    "\n",
    "peak=[]\n",
    "\n",
    "try:\n",
    "    peak_rank=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[5]/span')\n",
    "    for i in peak_rank:        \n",
    "        peak1=i.text\n",
    "        peak.append(peak1)\n",
    "except NoSuchElementException:\n",
    "    peak.append(\"-\")\n",
    "peak\n",
    "time.sleep(5)\n",
    "\n",
    "wob=[]\n",
    "\n",
    "try:\n",
    "    wob_rank=driver.find_elements(By.XPATH,'/html/body/div[4]/main/div[2]/div[3]/div/div/div/div[2]/div/ul/li[4]/ul/li[6]/span')\n",
    "    for i in wob_rank:        \n",
    "        wob1=i.text\n",
    "        wob.append(wob1)\n",
    "except NoSuchElementException:\n",
    "    wob.append(\"-\")\n",
    "wob\n",
    "time.sleep(5)\n",
    "\n",
    "print(len(Song_list),len(Artist),len(last),len(peak),len(wob))\n",
    "\n",
    "df=pd.DataFrame({\"Song name\":Song_list,\"Artist name\":Artist,\"Last week Rank\":last,\"Peak Rank\":peak,\"Weeks on Board\":wob})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6eea8ed",
   "metadata": {},
   "source": [
    "# Q.No.7 Scrape the details of Data science recruiters from naukri.com. Url = https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6aed897",
   "metadata": {},
   "source": [
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1307208d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills they hire for</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Santhosh Kumar</td>\n",
       "      <td>Associate Manager Human Resources</td>\n",
       "      <td>Maveric Systems</td>\n",
       "      <td>It Recruitment, Campus Recruitment, Campus Hir...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gauri Bhosle</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>TCRC</td>\n",
       "      <td>Operation Executive, Jr. Chemist/ Chemist, Aud...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aditya pungavkar</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>IP ASSOCIATES</td>\n",
       "      <td>Autocad, Google Sketchup, Architectural Design...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Surendra R</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>DSR Design &amp; Engineering Solutions</td>\n",
       "      <td>Design Engineering, AutoCAD, Solid Works</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Neha Pandey</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Ingenious E-Brain Solutions Private Limited</td>\n",
       "      <td>B.tech, Operations, Business Development, Busi...</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vinita Raut</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Xpansion HR Solutions Private Limited</td>\n",
       "      <td>Bde, Accounting, Education Counseling, Sales, ...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BALA Sakthivelmuthu</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>E Vel</td>\n",
       "      <td>Html, Css, Javascript, Ui Development, Java, A...</td>\n",
       "      <td>Madurai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Merino</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Precission Fabrics India Pvt Ltd</td>\n",
       "      <td>Production</td>\n",
       "      <td>Coimbatore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name                        Designation  \\\n",
       "0       Santhosh Kumar  Associate Manager Human Resources   \n",
       "1         Gauri Bhosle                    Human Resources   \n",
       "2     aditya pungavkar                  Company Recruiter   \n",
       "3           Surendra R                  Company Recruiter   \n",
       "4          Neha Pandey                  Company Recruiter   \n",
       "5          Vinita Raut                  Company Recruiter   \n",
       "6  BALA Sakthivelmuthu                  Company Recruiter   \n",
       "7               Merino                  Company Recruiter   \n",
       "\n",
       "                                       Company  \\\n",
       "0                              Maveric Systems   \n",
       "1                                         TCRC   \n",
       "2                                IP ASSOCIATES   \n",
       "3           DSR Design & Engineering Solutions   \n",
       "4  Ingenious E-Brain Solutions Private Limited   \n",
       "5        Xpansion HR Solutions Private Limited   \n",
       "6                                        E Vel   \n",
       "7             Precission Fabrics India Pvt Ltd   \n",
       "\n",
       "                                Skills they hire for                  Location  \n",
       "0  It Recruitment, Campus Recruitment, Campus Hir...                   Chennai  \n",
       "1  Operation Executive, Jr. Chemist/ Chemist, Aud...                    Mumbai  \n",
       "2  Autocad, Google Sketchup, Architectural Design...                      Pune  \n",
       "3           Design Engineering, AutoCAD, Solid Works  Hyderabad / Secunderabad  \n",
       "4  B.tech, Operations, Business Development, Busi...                   Gurgaon  \n",
       "5  Bde, Accounting, Education Counseling, Sales, ...                      Pune  \n",
       "6  Html, Css, Javascript, Ui Development, Java, A...                   Madurai  \n",
       "7                                         Production                Coimbatore  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,ElementNotInteractableException\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.naukri.com/hr-recruiters-consultants\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "# Name\n",
    "#Designation\n",
    "# Company\n",
    "# Skills they hire for\n",
    "#Location\n",
    "\n",
    "Name=[]\n",
    "names=driver.find_elements(By.XPATH,'/html/body/div[3]/div[1]/div[1]/div[2]/div/div/div[1]/div[1]/div/div/div[1]/div[1]/p/a[1]/span')\n",
    "for i in names:\n",
    "    name1=i.text\n",
    "    Name.append(name1)\n",
    "Name\n",
    "time.sleep(5)\n",
    "\n",
    "desgn=[]\n",
    "try:\n",
    "    designation=driver.find_elements(By.XPATH,'/html/body/div[3]/div[1]/div[1]/div[2]/div/div/div[1]/div[1]/div/div/div[1]/div[1]/p/span[1]')\n",
    "    for i in designation:        \n",
    "        des1=i.text\n",
    "        desgn.append(des1)\n",
    "except NoSuchElementException:\n",
    "    desgn.append(\"No details available\")\n",
    "desgn\n",
    "time.sleep(5)   \n",
    "\n",
    "company=[]\n",
    "try:\n",
    "    comp=driver.find_elements(By.XPATH,'/html/body/div[3]/div[1]/div[1]/div[2]/div/div/div[1]/div[1]/div/div/div[1]/div[1]/p/a[2]/small')\n",
    "    for i in comp:        \n",
    "        comp1=i.text\n",
    "        company.append(comp1)\n",
    "except NoSuchElementException:\n",
    "    company.append(\"No details available\")\n",
    "company\n",
    "time.sleep(5)  \n",
    "\n",
    "Skills=[]\n",
    "try:\n",
    "    skill_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div[1]/div[1]/div[2]/div/div/div[1]/div[1]/div/div/div[1]/div[2]')\n",
    "    for i in skill_tags:        \n",
    "        skill1=i.text\n",
    "        Skills.append(skill1)\n",
    "except NoSuchElementException:\n",
    "    Skills.append(\"No details available\")\n",
    "Skills\n",
    "time.sleep(5)  \n",
    "\n",
    "Location=[]\n",
    "try:\n",
    "    loc_tags=driver.find_elements(By.XPATH,'/html/body/div[3]/div[1]/div[1]/div[2]/div/div/div[1]/div[1]/div/div/div[1]/div[1]/p/span[2]/small')\n",
    "    for i in loc_tags:        \n",
    "        loc1=i.text\n",
    "        Location.append(loc1)\n",
    "except NoSuchElementException:\n",
    "    Location.append(\"No details available\")\n",
    "Location\n",
    "time.sleep(5) \n",
    "\n",
    "df=pd.DataFrame({\"Name\":Name,\"Designation\":desgn,\"Company\":company,\"Skills they hire for\":Skills,\"Location\":Location})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa746050",
   "metadata": {},
   "source": [
    "# Q.NO.8 Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey- compare/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd36528",
   "metadata": {},
   "source": [
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34550286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book name       Author name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,ElementNotInteractableException\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "#Book name\n",
    "# Author name\n",
    "# Volumes sold\n",
    "#Publisher\n",
    "# Genre\n",
    "\n",
    "book_name=[]\n",
    "try:\n",
    "    books=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[2]')\n",
    "    for i in books:\n",
    "        book1=i.text\n",
    "        book_name.append(book1)\n",
    "except NoSuchElementException:\n",
    "    book_name.append(\"No details available\")\n",
    "book_name\n",
    "time.sleep(5)\n",
    "\n",
    "author_name=[]\n",
    "try:\n",
    "    authors=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]')\n",
    "    for i in authors:\n",
    "        author1=i.text\n",
    "        author_name.append(author1)\n",
    "except NoSuchElementException:\n",
    "    author_name.append(\"No details available\")\n",
    "author_name\n",
    "time.sleep(5)\n",
    "\n",
    "volumes_sold=[]\n",
    "try:\n",
    "    volumes=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[4]')\n",
    "    for i in volumes:\n",
    "        volumes1=i.text\n",
    "        volumes_sold.append(volumes1)\n",
    "except NoSuchElementException:\n",
    "    volumes_sold.append(\"No details available\")\n",
    "volumes_sold\n",
    "time.sleep(5)\n",
    "\n",
    "Publisher=[]\n",
    "try:\n",
    "    pub=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[5]')\n",
    "    for i in pub:\n",
    "        pub1=i.text\n",
    "        Publisher.append(pub1)\n",
    "except NoSuchElementException:\n",
    "    Publisher.append(\"No details available\")\n",
    "Publisher\n",
    "time.sleep(5)\n",
    "\n",
    "Genre=[]\n",
    "try:\n",
    "    gen=driver.find_elements(By.XPATH,'/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[6]')\n",
    "    for i in gen:\n",
    "        gen1=i.text\n",
    "        Genre.append(gen1)\n",
    "except NoSuchElementException:\n",
    "    Genre(\"No details available\")\n",
    "Genre\n",
    "\n",
    "df=pd.DataFrame({\"Book name\":book_name,\"Author name\":author_name,\"Volumes Sold\":volumes_sold,\"Publisher\":Publisher,\"Genre\":Genre})\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d310490",
   "metadata": {},
   "source": [
    "# Q.No.9:Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b7e119",
   "metadata": {},
   "source": [
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f8cc23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,100,204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,190,475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>994,209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>294,237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>253,343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>61,987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>199,948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018– )</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>247,002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House     (2018– )    Drama, Horror, Mystery   \n",
       "\n",
       "    Runtime Ratings      Votes  \n",
       "0    57 min     9.2  2,100,204  \n",
       "1    51 min     8.7  1,190,475  \n",
       "2    44 min     8.1    994,209  \n",
       "3    60 min     7.5    294,237  \n",
       "4    43 min     7.6    253,343  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     50,377  \n",
       "96   50 min     7.8     61,987  \n",
       "97   42 min     8.1    199,948  \n",
       "98   45 min     7.1     41,715  \n",
       "99  572 min     8.6    247,002  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,ElementNotInteractableException\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "Name=[]\n",
    "try:\n",
    "    names=driver.find_elements(By.XPATH,'/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/h3/a')\n",
    "    for i in names:\n",
    "        name1=i.text\n",
    "        Name.append(name1)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"No details available\")\n",
    "Name\n",
    "  \n",
    "yos=[]\n",
    "try:\n",
    "    year=driver.find_elements(By.XPATH,'/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/h3/span[2]')\n",
    "    for i in year:\n",
    "        year1=i.text\n",
    "        yos.append(year1)\n",
    "except NoSuchElementException:\n",
    "    yos.append(\"No details available\")\n",
    "yos\n",
    "\n",
    "Genre=[]\n",
    "try:\n",
    "    genre=driver.find_elements(By.XPATH,'/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/p[1]/span[5]')\n",
    "    for i in genre:\n",
    "        genre1=i.text\n",
    "        Genre.append(genre1)\n",
    "except NoSuchElementException:\n",
    "    Genre.append(\"No details available\")\n",
    "Genre\n",
    "\n",
    "\n",
    "Ratings=[]\n",
    "try:\n",
    "    rating=driver.find_elements(By.XPATH,'/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/div[1]/div[1]/span[2]')\n",
    "    for i in rating:\n",
    "        rating1=i.text\n",
    "        Ratings.append(rating1)\n",
    "except NoSuchElementException:\n",
    "    Ratings.append(\"No details available\")\n",
    "Ratings\n",
    "\n",
    "Runtime=[]\n",
    "try:\n",
    "    run=driver.find_elements(By.XPATH,'/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/p[1]/span[3]')\n",
    "    for i in run:\n",
    "        run1=i.text\n",
    "        Runtime.append(run1)\n",
    "except NoSuchElementException:\n",
    "    Runtime.append(\"No details available\")\n",
    "Runtime\n",
    "\n",
    "Votes=[]\n",
    "try:\n",
    "    vote=driver.find_elements(By.XPATH,'/html/body/div[2]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/p[4]/span[2]')\n",
    "    for i in vote:\n",
    "        vote1=i.text\n",
    "        Votes.append(vote1)\n",
    "except NoSuchElementException:\n",
    "    Votes.append(\"No details available\")\n",
    "Votes\n",
    "\n",
    "\n",
    "print(len(Name),len(yos),len(Genre),len(Ratings),len(Runtime),len(Votes))\n",
    "\n",
    "df=pd.DataFrame({\"Name\":Name,\"Year Span\":yos,\"Genre\":Genre,\"Runtime\":Runtime,\"Ratings\":Ratings,\"Votes\":Votes})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939ed49b",
   "metadata": {},
   "source": [
    "# Q.No.10 :Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605579f1",
   "metadata": {},
   "source": [
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04616fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Default Tasks</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data_type         Default Tasks  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute_type No_of_instances No_of_attributes   Year  \n",
       "0    Categorical, Integer, Real            4177                8   1995   \n",
       "1          Categorical, Integer           48842               14   1996   \n",
       "2    Categorical, Integer, Real             798               38          \n",
       "3                   Categorical           37711              294   1998   \n",
       "4    Categorical, Integer, Real             452              279   1998   \n",
       "..                           ...             ...              ...    ...  \n",
       "617               Integer, Real           75840              525   2020   \n",
       "618               Integer, Real             400               50   2020   \n",
       "619                                        1014                7   2020   \n",
       "620                        Real           10129               16   2021   \n",
       "621                        Real            4000                2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException,ElementNotInteractableException\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\Win\\Desktop\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "driver.get(\"https://archive.ics.uci.edu/ml/index.php\")\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "dataset=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/span/b/a')\n",
    "dataset.click()\n",
    "#Dataset name\n",
    "# Data type\n",
    "#Task\n",
    "#Attribute type\n",
    "# No of instances\n",
    "#No of attribute\n",
    "# Year\n",
    "\n",
    "dataset_name=[]\n",
    "try:\n",
    "    dataset=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]/table/tbody/tr/td[2]/p/b/a')\n",
    "    for i in dataset:\n",
    "        data=i.text\n",
    "        dataset_name.append(data)\n",
    "except NoSuchElementException:\n",
    "    dataset_name.append(\"No details available\")\n",
    "dataset_name\n",
    "time.sleep(3)\n",
    "\n",
    "default_task=[]\n",
    "try:\n",
    "    tasks=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]')\n",
    "    for i in tasks[1:]:\n",
    "        task1=i.text\n",
    "        default_task.append(task1)\n",
    "except NoSuchElementException:\n",
    "    default_task.append(\"No details available\")\n",
    "default_task\n",
    "time.sleep(3)\n",
    "\n",
    "data_type=[]\n",
    "try:\n",
    "    types=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]/p')\n",
    "    for i in types[1:]:\n",
    "        typ1=i.text\n",
    "        data_type.append(typ1)\n",
    "except NoSuchElementException:\n",
    "    data_type.append(\"No details available\")\n",
    "data_type\n",
    "time.sleep(3)\n",
    "          \n",
    "attribute=[]\n",
    "try:\n",
    "    att1=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]/p')\n",
    "    for i in att1[1:]:\n",
    "        att2=i.text\n",
    "        attribute.append(att2)\n",
    "except NoSuchElementException:\n",
    "    attribute.append(\"No details available\")\n",
    "attribute\n",
    "time.sleep(3)\n",
    "\n",
    "NOI=[]\n",
    "try:\n",
    "    noi=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]/p')\n",
    "    for i in noi[1:]:\n",
    "        noi2=i.text\n",
    "        NOI.append(noi2)\n",
    "except NoSuchElementException:\n",
    "    NOI.append(\"No details available\")\n",
    "NOI\n",
    "time.sleep(3)\n",
    "\n",
    "NOA=[]\n",
    "try:\n",
    "    noa=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]/p')\n",
    "    for i in noa[1:]:\n",
    "        noa1=i.text\n",
    "        NOA.append(noa1)\n",
    "except NoSuchElementException:\n",
    "    NOA.append(\"No details available\")\n",
    "NOA\n",
    "time.sleep(3)\n",
    "\n",
    "YEAR=[]\n",
    "try:\n",
    "    year=driver.find_elements(By.XPATH,'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]/p')\n",
    "    for i in year[1:]:\n",
    "        year1=i.text\n",
    "        YEAR.append(year1)\n",
    "except NoSuchElementException:\n",
    "    YEAR.append(\"No details available\")\n",
    "YEAR\n",
    "\n",
    "df=pd.DataFrame({'Dataset Name':dataset_name,\n",
    "                'Data_type':data_type,\n",
    "                'Default Tasks':default_task,\n",
    "                'Attribute_type':attribute,\n",
    "                'No_of_instances':NOI,\n",
    "                'No_of_attributes':NOA,\n",
    "                'Year':YEAR})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a8292c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
